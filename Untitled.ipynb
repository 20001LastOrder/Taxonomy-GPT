{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2707815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c62ba846-f7a8-4117-ba7e-0955fec796cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPTNeoForSequenceClassification, GPTNeoForCausalLM, GPT2Tokenizer\n",
    "from model import GPTNeoForSequenceClassificationBinary\n",
    "\n",
    "model = GPTNeoForSequenceClassificationBinary.from_pretrained(\"/notebooks/results/checkpoint-3295\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e6cb6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2048, out_features=1, bias=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58aee8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import get_taxonomy_dataset, get_taxonomy_dataset_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3ee3e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-7aa8b1b23cb12395\n",
      "Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-7aa8b1b23cb12395/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "Parameter 'function'=<function get_taxonomy_dataset_binary.<locals>.<lambda> at 0x7f1a76d37c10> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0a7b68996f84964bef4a1afe88d3cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29754 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = get_taxonomy_dataset_binary('/notebooks/taxonomy.csv', entire_dataset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da09b24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd40a2d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd5c84cd58e4a8a960e876c29c17abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/465 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers.data.data_collator import DataCollatorWithPadding\n",
    "from tqdm.notebook import tqdm\n",
    "import torch \n",
    "\n",
    "results = []\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "train_dataloader = DataLoader(\n",
    "    dataset[\"test\"], batch_size=64,  collate_fn=data_collator\n",
    ")\n",
    "with torch.no_grad():\n",
    "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
    "        batch = batch.to('cuda')\n",
    "        output = model(batch['input_ids'])\n",
    "        predicted_labels = output.logits > 0\n",
    "        results.extend(predicted_labels.cpu().detach().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c4c9cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [r[0] for r in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b29e48fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/notebooks/taxonomy.csv')\n",
    "df['predicted_labels'] = results\n",
    "\n",
    "df.to_csv('/notebooks/results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0af187d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>parent</th>\n",
       "      <th>child</th>\n",
       "      <th>group</th>\n",
       "      <th>flag</th>\n",
       "      <th>predicted_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>space</td>\n",
       "      <td>mathematical_space</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>mathematical_space</td>\n",
       "      <td>manifold</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>mathematical_space</td>\n",
       "      <td>metric_space</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>metric_space</td>\n",
       "      <td>Euclidean_space</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>metric_space</td>\n",
       "      <td>Hilbert_space</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29749</th>\n",
       "      <td>29749</td>\n",
       "      <td>bridgehead</td>\n",
       "      <td>strike_zone</td>\n",
       "      <td>514</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29750</th>\n",
       "      <td>29750</td>\n",
       "      <td>Waldenses</td>\n",
       "      <td>Karaites</td>\n",
       "      <td>493</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29751</th>\n",
       "      <td>29751</td>\n",
       "      <td>walk_through</td>\n",
       "      <td>appear</td>\n",
       "      <td>726</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29752</th>\n",
       "      <td>29752</td>\n",
       "      <td>apple_aphid</td>\n",
       "      <td>pale_chrysanthemum_aphid</td>\n",
       "      <td>139</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29753</th>\n",
       "      <td>29753</td>\n",
       "      <td>protest_march</td>\n",
       "      <td>sit-down</td>\n",
       "      <td>93</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29754 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0              parent                     child  group   flag  \\\n",
       "0               0               space        mathematical_space      0   True   \n",
       "1               1  mathematical_space                  manifold      0   True   \n",
       "2               2  mathematical_space              metric_space      0   True   \n",
       "3               3        metric_space           Euclidean_space      0   True   \n",
       "4               4        metric_space             Hilbert_space      0   True   \n",
       "...           ...                 ...                       ...    ...    ...   \n",
       "29749       29749          bridgehead               strike_zone    514  False   \n",
       "29750       29750           Waldenses                  Karaites    493  False   \n",
       "29751       29751        walk_through                    appear    726  False   \n",
       "29752       29752         apple_aphid  pale_chrysanthemum_aphid    139  False   \n",
       "29753       29753       protest_march                  sit-down     93  False   \n",
       "\n",
       "       predicted_labels  \n",
       "0                  True  \n",
       "1                  True  \n",
       "2                  True  \n",
       "3                 False  \n",
       "4                 False  \n",
       "...                 ...  \n",
       "29749             False  \n",
       "29750             False  \n",
       "29751             False  \n",
       "29752             False  \n",
       "29753             False  \n",
       "\n",
       "[29754 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "1db493ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "text = 'I am doing the taxonomy research. I think inauspiciousness is a subtopic of'\n",
    "encode = tokenizer.encode(text, return_tensors='pt')\n",
    "output = model.generate(encode, max_new_tokens=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "1a157e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am doing the taxonomy research. I think inauspiciousness is a subtopic of subtopic<|endoftext|>'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9fb28294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c6d3c80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3420)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0bb4838",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "556a1df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 25]) torch.Size([64, 25])\n",
      "torch.Size([64, 25]) torch.Size([64, 25])\n",
      "torch.Size([64, 26]) torch.Size([64, 26])\n",
      "torch.Size([64, 23]) torch.Size([64, 23])\n",
      "torch.Size([64, 23]) torch.Size([64, 23])\n",
      "torch.Size([64, 24]) torch.Size([64, 24])\n",
      "torch.Size([64, 25]) torch.Size([64, 25])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from dataset import DataCollatorWithPaddingAndMasking\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPaddingAndMasking(tokenizer)\n",
    "train_dataloader = DataLoader(\n",
    "    dataset[\"train\"], batch_size=64,  collate_fn=data_collator\n",
    ")\n",
    "\n",
    "for step, batch in enumerate(train_dataloader):\n",
    "    print(batch[\"label_mask\"].shape, batch['input_ids'].shape)\n",
    "    if step > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01d16156",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Expected size 6 but got size 10 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/notebooks/Untitled.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bwidespread-discover-occupied-educational.trycloudflare.com/notebooks/Untitled.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m a \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([[\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m6\u001b[39m]])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bwidespread-discover-occupied-educational.trycloudflare.com/notebooks/Untitled.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m b \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([[\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m6\u001b[39m, \u001b[39m7\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m9\u001b[39m, \u001b[39m10\u001b[39m]])\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bwidespread-discover-occupied-educational.trycloudflare.com/notebooks/Untitled.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m torch\u001b[39m.\u001b[39;49mcat((a, b))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Expected size 6 but got size 10 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "from torch.nn import functional\n",
    "import torch\n",
    "a = torch.tensor([[1, 2, 3, 4, 5, 6]])\n",
    "b = torch.tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]])\n",
    "\n",
    "torch.cat((a, b), pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e0c3813e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = \"sample input text to generate\"\n",
    "encoding = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "output=model(encoding)\n",
    "torch.allclose(output.logits, full_logits[:, :encoding.shape[1], :], atol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71405eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_prompt_test(parent_n,child_n):\n",
    "  text_index = tokenizer.encode('I am doing the Taxonomy research. I think {child} is a subtopic of {parent}'.format(child=child_n, parent=parent_n),add_prefix_space=True)\n",
    "  v_remove=tokenizer.encode(parent_n+\" \" +child_n,add_prefix_space=True)\n",
    "  text_index_input=[i for i  in text_index if i not in set(v_remove)]\n",
    "  vector = model.transformer.wte.weight[text_index_input,:]\n",
    "  output=model(inputs_embeds=vector)\n",
    "  res_v=torch.argmax(output.logits,dim=1)\n",
    "  return res_v,text_index_input,text_index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
