{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Generate wordnet dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Data Preprocessing\n",
    "Adapted from: https://github.com/IBM/gnn-taxo-construction/blob/7ebaaf5ec856caf47a7b26a5d5da462f9b37fd17/preprocess.py\n",
    "'''\n",
    "import itertools\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import codecs\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "def get_filtered_root(T, term_count, topk):\n",
    "    cur_ct = [term_count[w] for w in T.V]\n",
    "    cur_ct_idx = np.argsort(cur_ct)\n",
    "    return set([T.V[idx] for idx in cur_ct_idx[-topk:]])\n",
    "\n",
    "def isHyper(taxo, hypo, hyper):\n",
    "    while hypo in taxo:\n",
    "        if taxo[hypo] == hyper:\n",
    "            return True\n",
    "        hypo = taxo[hypo]\n",
    "    return False\n",
    "\n",
    "def isEdge(taxo, hypo, hyper):\n",
    "    if hypo not in taxo:\n",
    "        return False\n",
    "    return taxo[hypo] == hyper\n",
    "\n",
    "class node:\n",
    "    def __init__(self, parent, name, level):\n",
    "        self.parent = parent\n",
    "        self.name = name\n",
    "        self.children = []\n",
    "        self.level = level\n",
    "\n",
    "\n",
    "class Tree():\n",
    "    def __init__(self, rootname, hypo2hyper, root_given, filter_root, term_count, allow_up, filename='',\n",
    "                 term_conv=None):\n",
    "        self.terms = set(hypo2hyper)\n",
    "        ##########\n",
    "        root = set()\n",
    "        root.add(rootname)\n",
    "        self.terms = self.terms.union(root)\n",
    "        ##########\n",
    "        self.term_conv = term_conv\n",
    "        self.non_leaf_terms = set([v[0] for v in hypo2hyper.values()])\n",
    "        if 'root007' in self.non_leaf_terms:\n",
    "            self.non_leaf_terms.remove('root007')\n",
    "        self.term2id = {t: ct for ct, t in enumerate(self.non_leaf_terms)}\n",
    "\n",
    "        for term in self.terms - self.non_leaf_terms:\n",
    "            self.term2id[term] = len(self.term2id)\n",
    "        ###############################\n",
    "        self.terms = set(self.term2id)\n",
    "        ###############################\n",
    "        self.id2term = {v: k for k, v in self.term2id.items()}\n",
    "        self.taxo = {}\n",
    "        self.n_x2root_hyper = 0\n",
    "        self.n_x2root_edge = 0\n",
    "        self.rootname = rootname\n",
    "        self.filename = filename\n",
    "        self.last_pair = None\n",
    "        self.root_given = root_given\n",
    "        for k, v in hypo2hyper.items():\n",
    "            self.taxo[k] = v[0]\n",
    "            if v[0] == rootname:\n",
    "                self.n_x2root_edge += 1\n",
    "        self.hypo2hyper_set = set()\n",
    "        gold_onehot = np.zeros((len(self.non_leaf_terms), len(self.terms)))\n",
    "        for t1, t2 in itertools.permutations(self.terms, 2):\n",
    "            if isHyper(self.taxo, t1, t2):\n",
    "                self.hypo2hyper_set.add((t1, t2))\n",
    "                gold_onehot[self.term2id[t2]][self.term2id[t1]] = 1\n",
    "                if t2 == rootname:\n",
    "                    self.n_x2root_hyper += 1\n",
    "        self.gold_onehot = gold_onehot / np.linalg.norm(gold_onehot, axis=1)[:, np.newaxis]\n",
    "        self.max_height = 10\n",
    "        # V is the remaining vocab\n",
    "        # N is terms on the tree\n",
    "        self.allow_up = allow_up\n",
    "        self.curroot_first = None\n",
    "        self.hyper2hypo_candidate = defaultdict(set)\n",
    "        self.re_init()\n",
    "        if filter_root:\n",
    "            self.filtered_root = get_filtered_root(self, term_count, 10)\n",
    "        else:\n",
    "            self.filtered_root = None\n",
    "\n",
    "    def get_height(self, term):\n",
    "        return self.term_height[term]\n",
    "\n",
    "    def fragment_metric(self, display=False):\n",
    "        tmp_term2id = {t: ct for ct, t in enumerate(self.N)}\n",
    "        test_onehot = np.zeros((len(self.N), len(self.terms)))\n",
    "        for hypo, hyper in self.hypo2hyper_test_set:\n",
    "            test_onehot[tmp_term2id[hyper]][self.term2id[hypo]] = 1\n",
    "        # remove 0s rows\n",
    "        test_onehot = test_onehot[~np.all(test_onehot == 0, axis=1)]\n",
    "        # normalize |v| = 1\n",
    "        test_onehot = test_onehot / np.linalg.norm(test_onehot, axis=1)[:, np.newaxis]\n",
    "        qd = np.dot(self.gold_onehot, test_onehot.T)\n",
    "        tmp = np.argmax(qd, axis=1)\n",
    "        qd = np.amax(qd, axis=1)\n",
    "        if display:\n",
    "            print(self.hypo2hyper_test_set)\n",
    "            for t, i, score in zip(self.non_leaf_terms, tmp, qd):\n",
    "                print([self.id2term[idx] for idx, v in enumerate(self.gold_onehot[self.term2id[t]]) if v > 0])\n",
    "                print([self.id2term[idx] for idx, v in enumerate(test_onehot[i]) if v > 0])\n",
    "                print(score)\n",
    "        qd[qd < 0.2] = 0\n",
    "\n",
    "        res = sum(qd) / len(self.non_leaf_terms)\n",
    "        return res\n",
    "\n",
    "    def re_init(self):\n",
    "        self.taxo_test = {}\n",
    "        self.hypo2hyper_test_set = set()\n",
    "        self.hyper2hypo_edgeonly = defaultdict(list)\n",
    "        self.hyper2hypo_candidate = defaultdict(set)\n",
    "        # self.term_height = defaultdict(lambda: 1)\n",
    "        self.term_height = defaultdict(int)\n",
    "        self.V = list(self.terms)\n",
    "        self.cur_height = 1\n",
    "        if self.root_given:\n",
    "            self.V.remove(self.rootname)\n",
    "            self.N = [self.rootname]\n",
    "            self.curroot = self.rootname\n",
    "            self.term_height[self.curroot] = 1\n",
    "        elif self.allow_up:\n",
    "            # self.curroot = random.choice(self.V)\n",
    "            # self.curroot_first = self.curroot\n",
    "            if self.curroot_first is None:\n",
    "                # self.curroot = random.choice(self.V)\n",
    "                self.curroot = self.V[0]\n",
    "                self.curroot_first = self.curroot\n",
    "            else:\n",
    "                self.curroot = self.curroot_first\n",
    "            self.V.remove(self.curroot)\n",
    "            self.N = [self.curroot]\n",
    "            self.term_height[self.curroot] = 1\n",
    "        else:\n",
    "            self.N = []\n",
    "        self.prev_eval = 0\n",
    "\n",
    "    def save_best(self):\n",
    "        self.taxo_test_best = {k: v for k, v in self.taxo_test.items()}\n",
    "        self.hypo2hyper_test_set_best = set(self.hypo2hyper_test_set)\n",
    "        self.root_best = self.N[0]\n",
    "\n",
    "    def load_best(self):\n",
    "        self.taxo_test = {k: v for k, v in self.taxo_test_best.items()}\n",
    "        self.hypo2hyper_test_set = set(self.hypo2hyper_test_set_best)\n",
    "        self.N = [self.root_best]\n",
    "\n",
    "    def get_children(self, term):\n",
    "        return self.hyper2hypo_edgeonly[term]\n",
    "\n",
    "    def update(self, pair, test=False):\n",
    "        self.last_pair = pair\n",
    "        hypo = pair[0]\n",
    "        hyper = pair[1]\n",
    "        self.hyper2hypo_edgeonly[hyper].append(hypo)\n",
    "        if not test:\n",
    "            if not self.allow_up:\n",
    "                self.N.append(hypo)\n",
    "                try:\n",
    "                    self.V.remove(hypo)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(hypo, hyper)\n",
    "                    exit(2)\n",
    "            else:\n",
    "                if hypo == self.curroot:\n",
    "                    self.curroot = hyper\n",
    "                    self.N.append(hyper)\n",
    "                    self.V.remove(hyper)\n",
    "                    self.term_height[hyper] = 1\n",
    "                    for k in self.term_height:\n",
    "                        self.term_height[k] += 1\n",
    "                    self.cur_height += 1\n",
    "                else:\n",
    "                    self.N.append(hypo)\n",
    "                    self.V.remove(hypo)\n",
    "                    self.term_height[hypo] = self.term_height[hyper] + 1\n",
    "                    self.cur_height = max(self.cur_height, self.term_height[hypo])\n",
    "\n",
    "            assert len(self.V) + len(self.N) == len(self.terms)\n",
    "            if not self.allow_up and hyper == 'root007':\n",
    "                return\n",
    "        self.taxo_test[hypo] = hyper\n",
    "        cur = hypo\n",
    "        while cur in self.taxo_test:\n",
    "            self.hypo2hyper_test_set.add((hypo, self.taxo_test[cur]))\n",
    "            cur = self.taxo_test[cur]\n",
    "            # print 'pair selected:', pair, self.taxo_test, self.hypo2hyper_test_set\n",
    "\n",
    "    def update_edgefile(self, pair):\n",
    "        hypo = pair[0]\n",
    "        hyper = pair[1]\n",
    "        self.hyper2hypo_edgeonly[hyper].append(hypo)\n",
    "        # if hypo in self.taxo_test:\n",
    "        #     print '[warning]', hypo, 'already has a hypernym', self.taxo_test[hypo]\n",
    "        self.taxo_test[hypo] = hyper\n",
    "\n",
    "    def permute_ancestor_up2down(self):\n",
    "        def _permute_ancestor_up2down(cur_hyper, real_hyper):\n",
    "            for hypo in self.hyper2hypo_edgeonly[cur_hyper]:\n",
    "                self.hypo2hyper_test_set.add((hypo, real_hyper))\n",
    "                if hypo in self.hyper2hypo_edgeonly:\n",
    "                    _permute_ancestor_up2down(hypo, real_hyper)\n",
    "\n",
    "        for hyper in self.hyper2hypo_edgeonly:\n",
    "            _permute_ancestor_up2down(hyper, hyper)\n",
    "\n",
    "    def permute_ancestor(self):\n",
    "        for hypo in self.taxo_test:\n",
    "            cur = hypo\n",
    "            while cur in self.taxo_test:\n",
    "                self.hypo2hyper_test_set.add((hypo, self.taxo_test[cur]))\n",
    "                cur = self.taxo_test[cur]\n",
    "\n",
    "    def update_pairfile(self, pair):\n",
    "        hypo = pair[0]\n",
    "        hyper = pair[1]\n",
    "        self.hyper2hypo_edgeonly[hyper].append(hypo)\n",
    "        self.taxo_test[hypo] = hyper\n",
    "        cur = hypo\n",
    "        self.hypo2hyper_test_set.add((hypo, self.taxo_test[cur]))\n",
    "\n",
    "    def draw(self):\n",
    "        q = [self.curroot]\n",
    "        nextq = []\n",
    "        print(q)\n",
    "        while len(q) > 0:\n",
    "            cur = q.pop(0)\n",
    "            print(self.hyper2hypo_edgeonly[cur],)\n",
    "            nextq.extend(self.hyper2hypo_edgeonly[cur])\n",
    "            if len(q) == 0:\n",
    "                q = nextq\n",
    "                nextq = []\n",
    "                print\n",
    "\n",
    "    def eval(self, reward_type, reward_form):\n",
    "        cur_reward = self.evaluate(reward_type=reward_type)\n",
    "        if reward_form == 'per' or reward_form == 'last':\n",
    "            return cur_reward\n",
    "        elif reward_form == 'diff':\n",
    "            reward = cur_reward - self.prev_eval\n",
    "            self.prev_eval = cur_reward\n",
    "            return reward\n",
    "        else:\n",
    "            print(\"no such reward form:\", reward_form)\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def wrong_at(self, n_wrong, k):\n",
    "        if n_wrong <= k:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def evaluate(self, data=None, micro_data=None, wrong_at_data=None, reward_type='', output=False, return_all=False,\n",
    "                 display=False):\n",
    "        res_isHyper_Test = [i in self.hypo2hyper_set for i in self.hypo2hyper_test_set]\n",
    "        res_isEdge_Test = [self.taxo[k] == v for k, v in self.taxo_test.items()]\n",
    "        if len(res_isHyper_Test) == 0:\n",
    "            if len(self.N) == 0:\n",
    "                res_isHyper_Test = [False]\n",
    "                res_isEdge_Test = [False]\n",
    "            else:\n",
    "                if self.N[0] == self.rootname:\n",
    "                    res_isHyper_Test = [True]\n",
    "                    res_isEdge_Test = [True]\n",
    "                else:\n",
    "                    res_isHyper_Test = [False]\n",
    "                    res_isEdge_Test = [False]\n",
    "\n",
    "        n_hyper = sum(res_isHyper_Test)\n",
    "        n_edge = sum(res_isEdge_Test)\n",
    "        hyper_prec = n_hyper / float(len(res_isHyper_Test))\n",
    "        hyper_recall = n_hyper / float(len(self.hypo2hyper_set))\n",
    "        if hyper_prec == 0 and hyper_recall == 0:\n",
    "            hyper_f1 = 0\n",
    "        else:\n",
    "            hyper_f1 = 2 * hyper_recall * hyper_prec / (hyper_recall + hyper_prec)\n",
    "        edge_recall = n_edge / float(len(self.taxo) - 1)  # realroot -> 'root'\n",
    "        edge_prec = n_edge / float(len(res_isEdge_Test))\n",
    "        if edge_prec == 0 and edge_recall == 0:\n",
    "            edge_f1 = 0\n",
    "        else:\n",
    "            edge_f1 = 2 * edge_recall * edge_prec / (edge_recall + edge_prec)\n",
    "        if output or reward_type == 'print_each':\n",
    "            # print '#pairs (x, root):{} ** #edges (x, root):{}'.format(self.n_x2root_hyper, self.n_x2root_edge)\n",
    "            print(\"Hyper-Prec: {} / {} = {:.3f}\".format(sum(res_isHyper_Test), len(res_isHyper_Test), hyper_prec),)\n",
    "            print(\"Hyper-recall: {} / {} = {:.3f}\".format(sum(res_isHyper_Test), len(self.hypo2hyper_set),\n",
    "                                                          hyper_recall),)\n",
    "            print(\"Hyper-F1: {:.3f}\".format(hyper_f1),)\n",
    "            print(\"Edge-Prec: {} / {} = {:.3f}\".format(sum(res_isEdge_Test), len(self.taxo_test), edge_prec),)\n",
    "            print(\"Edge-recall = {} / {} = {:.3f}\".format(sum(res_isEdge_Test), len(self.taxo) - 1, edge_recall),)\n",
    "            print(\"Edge-F1 = {:.3f}\".format(edge_f1))\n",
    "            if reward_type != 'print_each':\n",
    "                return\n",
    "        if 'print' in reward_type:\n",
    "            cur_data = [0.] * len(data)\n",
    "            if not self.allow_up and self.N[0] == self.rootname:\n",
    "                cur_data[5] = 1.\n",
    "            elif self.allow_up and self.curroot == self.rootname:\n",
    "                cur_data[5] = 1.\n",
    "            cur_data[0] = hyper_f1\n",
    "            cur_data[1] = edge_f1\n",
    "            cur_data[2] = self.fragment_metric(display)\n",
    "            cur_data[3] = hyper_prec\n",
    "            cur_data[4] = hyper_recall\n",
    "            for i in range(len(data)):\n",
    "                data[i] += cur_data[i]\n",
    "            if reward_type == 'print_each':\n",
    "                print(self.filename, cur_data)\n",
    "\n",
    "            micro_data[0] += n_hyper\n",
    "            micro_data[1] += len(res_isHyper_Test)\n",
    "            micro_data[2] += len(self.hypo2hyper_set)\n",
    "\n",
    "            wrong_idx = 0\n",
    "            for k in [5, 10, 20, 30, 40]:\n",
    "                wrong_at_data[wrong_idx] += self.wrong_at(len(res_isHyper_Test) - n_hyper, k)\n",
    "                wrong_idx += 1\n",
    "                wrong_at_data[wrong_idx] += self.wrong_at(len(res_isEdge_Test) - n_edge, k)\n",
    "                wrong_idx += 1\n",
    "            return data, micro_data, wrong_at_data, (len(res_isHyper_Test) - n_hyper, len(res_isEdge_Test) - n_edge)\n",
    "        if return_all:\n",
    "            return hyper_prec, hyper_recall, hyper_f1, edge_prec, edge_recall, edge_f1, self.n_x2root_hyper, self.n_x2root_edge\n",
    "        elif reward_type == 'fragment':\n",
    "            return self.fragment_metric()\n",
    "        if reward_type == 'edge':\n",
    "            # if len(self.V) == 0:\n",
    "            #     return edge_f1 * 3\n",
    "            return edge_f1\n",
    "        elif reward_type == 'edge-prec':\n",
    "            return edge_prec\n",
    "        elif reward_type == 'edge-recall':\n",
    "            return edge_recall\n",
    "        elif reward_type == 'hyper':\n",
    "            return hyper_f1\n",
    "        elif reward_type == 'hyper-prec':\n",
    "            return hyper_prec\n",
    "        elif reward_type == 'hyper-recall':\n",
    "            return hyper_recall\n",
    "        elif reward_type == 'binary':\n",
    "            return int(self.taxo[self.last_pair[0]] == self.last_pair[1])\n",
    "\n",
    "        print('no such reward_type:', reward_type)\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @staticmethod\n",
    "    def f1_calc(p, r):\n",
    "        return round(2 * p * r / (p + r), 3)\n",
    "\n",
    "\n",
    "def copy_tree(tree, times, nolist=False):\n",
    "    if nolist:\n",
    "        return copy.deepcopy(tree)\n",
    "\n",
    "    return [copy.deepcopy(tree) for _ in range(times)]\n",
    "\n",
    "\n",
    "def read_tree(line):\n",
    "    level = 0\n",
    "    root = node(None, 'root007', level)\n",
    "    level += 1\n",
    "    curnode = root\n",
    "    term = ''\n",
    "    level_down, level_up = 0, 0\n",
    "    for c in line:\n",
    "        if c == '(':\n",
    "            level_down += 1\n",
    "        elif c == ' ' or c == '\\n':\n",
    "            curnode.children.append(node(curnode, term, level))\n",
    "            while level_down != 0:\n",
    "                level += 1\n",
    "                curnode = curnode.children[-1]\n",
    "                level_down -= 1\n",
    "            while level_up != 0:\n",
    "                level -= 1\n",
    "                curnode = curnode.parent\n",
    "                level_up -= 1\n",
    "            term = ''\n",
    "        elif c == ')':\n",
    "            level_up += 1\n",
    "        else:\n",
    "            term += c\n",
    "    return root\n",
    "\n",
    "\n",
    "def traverse(root, h):\n",
    "    #     print(root.level, root.name, '->', [i.name for i in root.children])\n",
    "    for i in root.children:\n",
    "        h[re.sub('_\\$_', '_', i.name)].append(re.sub('_\\$_', '_', root.name))\n",
    "    for i in root.children:\n",
    "        traverse(i, h)\n",
    "\n",
    "\n",
    "def read_tree_file(in_name, given_root, tree_start_index, data_split, filter_root=False, allow_up=True, noUnderscore=False):\n",
    "    trees = []\n",
    "    relations = []\n",
    "    # term_count = get_termcount()\n",
    "    term_count = None\n",
    "    with open(in_name) as f:\n",
    "        # each line is a tree\n",
    "        for data_split_tree_index, line in enumerate(f):\n",
    "            root = read_tree(line)\n",
    "            realroot = root.children[0].name\n",
    "            hypo2hyper_edgeonly = defaultdict(list)\n",
    "            # after traverse, edges of a tree are added to hypo2hyper\n",
    "            traverse(root, hypo2hyper_edgeonly)\n",
    "            for term, hypernym in hypo2hyper_edgeonly.items():\n",
    "#                 assert(len(hypernym) == 1):\n",
    "                if hypernym[0] != 'root007':\n",
    "                    relations.append((hypernym[0], term, tree_start_index + data_split_tree_index, data_split))\n",
    "            if noUnderscore:\n",
    "                hypo2hyper_edgeonly_noUnderscore = defaultdict(list)\n",
    "                for k, v in hypo2hyper_edgeonly.items():\n",
    "                    hypo2hyper_edgeonly_noUnderscore[re.sub('_', '', k)].append(re.sub('_', '', v[0]))\n",
    "                hypo2hyper_edgeonly = hypo2hyper_edgeonly_noUnderscore\n",
    "            trees.append(\n",
    "                Tree(realroot, hypo2hyper_edgeonly, root_given=given_root, filter_root=filter_root,\n",
    "                     term_count=term_count, allow_up=allow_up))\n",
    "    return trees, relations\n",
    "\n",
    "\n",
    "def read_edge_files(in_path, given_root=False, filter_root=False, allow_up=True, noUnderscore=False):\n",
    "    trees = []\n",
    "    for root, dirs, files in os.walk(in_path):\n",
    "        for filename in files:\n",
    "            if not filename.endswith('taxo'):\n",
    "                continue\n",
    "            file_path = root + filename\n",
    "            print('read_edge_files', file_path)\n",
    "            with codecs.open(file_path, 'r', 'utf-8') as f:\n",
    "                hypo2hyper_edgeonly = defaultdict(list)\n",
    "                terms = set()\n",
    "                noSpace2underscore = {}\n",
    "                for line in f:\n",
    "                    #print(line)\n",
    "                    hypo, hyper = line.strip().lower().split('\\t')[1:]\n",
    "                    hypo_noSpace = re.sub(' ', '', hypo)\n",
    "                    hyper_noSpace = re.sub(' ', '', hyper)\n",
    "                    hypo_ = re.sub(' ', '_', hypo)\n",
    "                    hyper_ = re.sub(' ', '_', hyper)\n",
    "                    #hypo_ = hypo\n",
    "                    #hyper_ = hyper\n",
    "\n",
    "\n",
    "                    noSpace2underscore[hypo_noSpace] = hypo_\n",
    "                    noSpace2underscore[hyper_noSpace] = hyper_\n",
    "                    if noUnderscore:\n",
    "                        terms.add(hypo_noSpace)\n",
    "                        terms.add(hyper_noSpace)\n",
    "                        hypo2hyper_edgeonly[hypo_noSpace].append(hyper_noSpace)\n",
    "                    else:\n",
    "                        terms.add(hypo_)\n",
    "                        terms.add(hyper_)\n",
    "                        hypo2hyper_edgeonly[hypo_].append(hyper_)\n",
    "                realroot = list(terms - set(hypo2hyper_edgeonly))[0]\n",
    "                hypo2hyper_edgeonly[realroot].append('root007')\n",
    "                trees.append(\n",
    "                    Tree(realroot, hypo2hyper_edgeonly, root_given=given_root, filter_root=filter_root,\n",
    "                         term_count=None, allow_up=allow_up, filename=filename, term_conv=noSpace2underscore))\n",
    "    return trees\n",
    "\n",
    "\n",
    "def load_candidate_from_pickle(trees):\n",
    "    for T in trees:\n",
    "        ct = 0\n",
    "        ct_substr = 0\n",
    "        hyper2hypo_w_freq = pickle.load(\n",
    "            open('../datasets/SemEval-2016/candidates_taxi/{}.pkl'.format(T.filename + '.candidate_w_freq'), 'rb'))\n",
    "        for hyper in hyper2hypo_w_freq:\n",
    "            for hypo in hyper2hypo_w_freq[hyper]:\n",
    "                if hyper2hypo_w_freq[hyper][hypo] >= 20:\n",
    "                    ct += 1\n",
    "                    T.hyper2hypo_candidate[hyper].add(hypo)\n",
    "        for hypo, hyper in itertools.permutations(T.terms, 2):\n",
    "            if hyper in hypo:\n",
    "                ct_substr += 1\n",
    "                T.hyper2hypo_candidate[hyper].add(hypo)\n",
    "        print('load {}+{}={} candidates for tree {} w. size {}'.format(ct, ct_substr,\n",
    "                                                                       ct + ct_substr,\n",
    "                                                                       T.filename,\n",
    "                                                                       len(T.terms)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of terms in training: 14800\n",
      "size of terms in the semeval: 14800\n",
      "size of terms added trial: 14800\n",
      "size of terms (semeval): 0\n",
      "num of trees which has no intersaction with label taxos: 761\n",
      "Trees need to be removed: 0\n",
      "Num included trees: 761\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Data Preprocessing\n",
    "Adapted from: https://github.com/IBM/gnn-taxo-construction/blob/7ebaaf5ec856caf47a7b26a5d5da462f9b37fd17/preprocess.py\n",
    "'''\n",
    "\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import codecs\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import os.path\n",
    "\n",
    "\n",
    "# Read the Semeval Taxonomies\n",
    "def read_files(in_path, given_root=False, filter_root=False, allow_up=True, noUnderscore=False):\n",
    "    trees = []\n",
    "    for root, dirs, files in os.walk(in_path):\n",
    "        for filename in files:\n",
    "            if not filename.endswith('taxo'):\n",
    "                continue\n",
    "            file_path = root + filename\n",
    "            print('read_edge_files', file_path)\n",
    "            with codecs.open(file_path, 'r', 'utf-8') as f:\n",
    "                hypo2hyper_edgeonly = []\n",
    "                terms = set()\n",
    "                for line in f:\n",
    "                    hypo, hyper = line.strip().lower().split('\\t')[1:]\n",
    "                    hypo_ = re.sub(' ', '_', hypo)\n",
    "                    hyper_ = re.sub(' ', '_', hyper)\n",
    "                    terms.add(hypo_)\n",
    "                    terms.add(hyper_)\n",
    "                    hypo2hyper_edgeonly.append([hypo_, hyper_])\n",
    "            print(len(terms))\n",
    "\n",
    "            trees.append([terms, hypo2hyper_edgeonly, filename])\n",
    "    return trees\n",
    "\n",
    "\n",
    "# Load the data from dataset_file\n",
    "def load_dataset(dataset_file, relations):\n",
    "    \"\"\"\n",
    "    Loads a dataset file\n",
    "    :param dataset_file: the file path\n",
    "    :return: a list of dataset instances, (x, y, relation)\n",
    "    \"\"\"\n",
    "    with codecs.open(dataset_file, 'r', 'utf-8') as f_in:\n",
    "        dataset = [tuple(line.strip().split('\\t')) for line in f_in]\n",
    "        dataset = {(x.lower(), y.lower()): relation for (x, y, relation) in dataset if relation in relations}\n",
    "    return dataset\n",
    "\n",
    "\n",
    "################### Get the labels/taxonomies ######################\n",
    "# Read all taxonomies\n",
    "\n",
    "trees, trees_train_relations = read_tree_file(\n",
    "    \"data/original_input/wn-bo-trees-4-11-50-train533.ptb\",\n",
    "    tree_start_index=0, data_split='train', given_root=False, filter_root=False, allow_up=True)\n",
    "trees_val, trees_val_relations = read_tree_file(\n",
    "    \"data/original_input/wn-bo-trees-4-11-50-dev114.ptb\",\n",
    "    tree_start_index=533, data_split='dev', given_root=False, filter_root=False, allow_up=True)\n",
    "trees_test, trees_test_relations = read_tree_file(\n",
    "    \"data/original_input/wn-bo-trees-4-11-50-test114.ptb\",\n",
    "    tree_start_index=533 + 114, data_split='test', given_root=False, filter_root=False, allow_up=True)\n",
    "trees_semeval = read_files('../data_creators/semeval_2016_task_13/TExEval-2_testdata_1.2/gs_taxo/EN/',\n",
    "                           given_root=True, filter_root=False, allow_up=False)\n",
    "trees_semeval_trial = read_files(\"../data_creators/semeval_2016_task_13/TExEval_trialdata_1.2/EN/\",\n",
    "                                 given_root=True, filter_root=False, allow_up=False)\n",
    "\n",
    "\n",
    "# Build the vocabulary\n",
    "vocab = set()\n",
    "for i in range(len(trees)):\n",
    "    vocab = vocab.union(trees[i].terms)\n",
    "for i in range(len(trees_val)):\n",
    "    vocab = vocab.union(trees_val[i].terms)\n",
    "for i in range(len(trees_test)):\n",
    "    vocab = vocab.union(trees_test[i].terms)\n",
    "print('size of terms in training:', len(vocab))\n",
    "\n",
    "for i in range(len(trees_semeval)):\n",
    "    vocab = vocab.union(trees_semeval[i][0])\n",
    "print('size of terms in the semeval:', len(vocab))\n",
    "for i in range(len(trees_semeval_trial)):\n",
    "    vocab = vocab.union(trees_semeval_trial[i][0])\n",
    "print('size of terms added trial:', len(vocab))\n",
    "\n",
    "vocab_semeval = set()\n",
    "for i in range(len(trees_semeval)):\n",
    "    vocab_semeval = vocab_semeval.union(trees_semeval[i][0])\n",
    "print('size of terms (semeval):', len(vocab_semeval))\n",
    "\n",
    "# Remove the overlapping taxonomies.\n",
    "tree_no_intersect = []\n",
    "count = 0\n",
    "falsecount = 0\n",
    "excluded_trees = []\n",
    "\n",
    "\n",
    "def convert_to_semeval_format(terms_set):\n",
    "    return set([term.lower().replace('_$_', '_') for term in terms_set])\n",
    "\n",
    "\n",
    "for i in range(len(trees)):\n",
    "    if len(convert_to_semeval_format(trees[i].terms) & vocab_semeval) == 0:\n",
    "        count = count + 1\n",
    "        tree_no_intersect.append(trees[i])\n",
    "    else:\n",
    "        falsecount = falsecount + 1\n",
    "        excluded_terms = set(trees[i].terms)\n",
    "        excluded_trees.append(excluded_terms)\n",
    "\n",
    "for i in range(len(trees_val)):\n",
    "    if len(convert_to_semeval_format(trees_val[i].terms) & vocab_semeval) == 0:\n",
    "        count = count + 1\n",
    "        tree_no_intersect.append(trees_val[i])\n",
    "    else:\n",
    "        falsecount = falsecount + 1\n",
    "        excluded_terms = set(trees_val[i].terms)\n",
    "        excluded_trees.append(excluded_terms)\n",
    "\n",
    "for i in range(len(trees_test)):\n",
    "    if len(convert_to_semeval_format(trees_test[i].terms) & vocab_semeval) == 0:\n",
    "        count = count + 1\n",
    "        tree_no_intersect.append(trees_test[i])\n",
    "    else:\n",
    "        falsecount = falsecount + 1\n",
    "        excluded_terms = set(trees_test[i].terms)\n",
    "        excluded_trees.append(excluded_terms)\n",
    "print('num of trees which has no intersaction with label taxos:', count)\n",
    "print('Trees need to be removed:', falsecount)\n",
    "\n",
    "### Save bansal 2014 trees.\n",
    "data_splits_and_tree_start_indices = {'train': {'num_trees': 533, 'tree_start_index': 0},\n",
    "        'dev': {'num_trees': 114, 'tree_start_index': 533},\n",
    "        'test': {'num_trees': 114, 'tree_start_index': 647}}\n",
    "\n",
    "df = pd.DataFrame(trees_train_relations + trees_val_relations + trees_test_relations)\n",
    "\n",
    "\n",
    "### Save bansal 2014 trees without semeval terms.\n",
    "df_no_semeval = pd.DataFrame()\n",
    "df.columns = ['hypernym', 'term', 'tree_id', 'data_split']\n",
    "num_included = 0\n",
    "for tree_id in set(df.tree_id):\n",
    "    tree_df = df[df.tree_id == tree_id]\n",
    "    tree_terms = set(tree_df.term).union(tree_df.hypernym)\n",
    "    if tree_terms not in excluded_trees:\n",
    "        num_included += 1\n",
    "        df_no_semeval = df_no_semeval.append(tree_df, ignore_index=True)\n",
    "print(f'Num included trees: {num_included}')\n",
    "df_no_semeval.columns=['parent','child','group','type']\n",
    "df_no_semeval.to_csv('data/train/bansal_wordnet_true_pairs.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create False pairs for test eveluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flase_gen_v2(df):\n",
    "    list_pair=[]\n",
    "    list_group=[]\n",
    "    list_node=[]\n",
    "    for num in list(pd.unique(df.group)):\n",
    "        df_test=df[df.group==num][['parent','child']]\n",
    "        list_check=list(pd.unique(df_test[['parent', 'child']].values.ravel('K')))\n",
    "        for i in list_check:\n",
    "            list_node.append(i)\n",
    "            list_pair.append([x for x in list_check if x != i])\n",
    "            list_group.append(num)\n",
    "    df_res= pd.DataFrame(\n",
    "      {'parent': list_node,\n",
    "      'child': list_pair,\n",
    "      'group': list_group\n",
    "      })\n",
    "    df_f=df_res.explode('child').dropna()\n",
    "    df_f_res=df_f[~df_f.duplicated(subset=['parent','child'], keep=False)]\n",
    "    df['flag']='True'\n",
    "    df_input=df_f_res.merge(df[['parent','child','flag']],on=['parent','child'],how='left')\n",
    "    df_input.flag=df_input.flag.fillna('False')\n",
    "    return df_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=df_no_semeval[df_no_semeval.type=='test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fandi\\Anaconda3\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df_test_res=flase_gen_v2(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_res.to_csv('data/evaluation/wordnet_all_false_july4_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
