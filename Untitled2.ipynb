{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5558b9a2-f57a-48e8-8019-231067759e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51418cab41214d29a27abff76cdbae13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-1.3B and are newly initialized: ['transformer.h.7.attn.attention.bias', 'transformer.h.19.attn.attention.bias', 'transformer.h.1.attn.attention.bias', 'transformer.h.23.attn.attention.bias', 'transformer.h.3.attn.attention.bias', 'score.weight', 'transformer.h.5.attn.attention.bias', 'transformer.h.15.attn.attention.bias', 'transformer.h.17.attn.attention.bias', 'transformer.h.13.attn.attention.bias', 'transformer.h.11.attn.attention.bias', 'transformer.h.9.attn.attention.bias', 'transformer.h.21.attn.attention.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from transformers import GPTNeoForSequenceClassification, GPTNeoForCausalLM, GPT2Tokenizer\n",
    "from model import GPTNeoForSequenceClassificationBinary\n",
    "import lightning.pytorch as pl\n",
    "from model import GPTSequenceClassifiationModule\n",
    "model = GPTSequenceClassifiationModule.load_from_checkpoint(\"/notebooks/runs/model.ckpt\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "812ecc6f-25f8-432b-be56-5185f0506832",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model=model.eval()\n",
    "model=model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eadbc954-5449-4585-bd4b-34089b924bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-9ee1c420eec116cd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-9ee1c420eec116cd/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c45133b97d4847df93f906bdd110878e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1583ef019a214516b803f592bbbec182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function get_taxonomy_dataset_binary.<locals>.<lambda> at 0x7f0caaff8430> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-9ee1c420eec116cd/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cb9f0a1a0be4cc4b166f3f94028ff8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17461 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dataset import get_taxonomy_dataset, get_taxonomy_dataset_binary\n",
    "dataset = get_taxonomy_dataset_binary('/notebooks/test_all.csv', entire_dataset=True,remove_columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cd59f06-9b2f-4bf6-913d-5b6565daf4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': Dataset({\n",
       "     features: ['input_ids', 'labels'],\n",
       "     num_rows: 17461\n",
       " })}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaffe6cf-76fe-4af8-ab60-49b3dbdd29d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dataset(example,tokenizer):\n",
    "    prompt_template = \"I am doing the taxonomy research. I think {child} is a subtopic of {parent}\"\n",
    "    prompt = prompt_template.format(child=example['child'], parent=example['parent'])\n",
    "    example['input_ids'] = tokenizer.encode(prompt)\n",
    "    return example\n",
    "def test_dataloader(str_path,batch_size):\n",
    "    dataset= get_taxonomy_dataset_binary(str_path,entire_dataset=True)\n",
    "    dataset = dataset['test']\n",
    "    dataset = dataset.map(lambda example: format_dataset(example,tokenizer))\n",
    "    dataset = dataset.remove_columns(['child', 'parent', 'group'])\n",
    "\n",
    "    return torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=DataCollatorWithPadding(tokenizer),\n",
    "        num_workers=4,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "610f19f2-1d4c-4c89-876e-73102509d29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-9ee1c420eec116cd\n",
      "Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-9ee1c420eec116cd/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "473f488c65e84f99a1542c1e6fc06ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17461 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057eba4f9efa4973b98874855fdeefce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17461 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f1d928c4cb849d2b285b27a3fd73cb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/273 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers.data.data_collator import DataCollatorWithPadding\n",
    "from tqdm.notebook import tqdm\n",
    "import torch \n",
    "\n",
    "results = []\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "testdataloader = test_dataloader('/notebooks/test_all.csv', 64)\n",
    "with torch.no_grad():\n",
    "    for step, batch in enumerate(tqdm(testdataloader)):\n",
    "        batch = batch.to('cuda')\n",
    "        output = model(batch['input_ids'], batch['attention_mask'])\n",
    "        predicted_labels = torch.sigmoid(output)\n",
    "        results.extend(predicted_labels.cpu().detach().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84f2bd49-6192-4f1b-a60b-899a2469380f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('/notebooks/test_all.csv')\n",
    "df['predict'] = results\n",
    "df['pred_flag']=[True if i>0.5 else False for i in df['predict']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7c0e649-4195-4b5c-b0c6-45d24ae37ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "17456     True\n",
       "17457     True\n",
       "17458     True\n",
       "17459     True\n",
       "17460     True\n",
       "Name: flag, Length: 17461, dtype: bool"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ac1c6a8-6381-41eb-a172-a812b4cff14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         True\n",
       "1         True\n",
       "2         True\n",
       "3         True\n",
       "4         True\n",
       "         ...  \n",
       "17456     True\n",
       "17457     True\n",
       "17458    False\n",
       "17459     True\n",
       "17460    False\n",
       "Name: pred_flag, Length: 17461, dtype: bool"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d52d0e8-0b4e-4b97-b35a-35e51ffa2258",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/notebooks/test_all_res_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee92ee0e-b8a9-4647-8a74-1faff2fb6aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6979964932536581\n",
      "0.673341222263191\n",
      "0.7447123271619405\n",
      "0.8506958364354847\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "y_test=df['flag']\n",
    "y_pred=df['pred_flag']\n",
    "print(f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(recall_score(y_test, y_pred, average=\"macro\"))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8559710-0b31-4e13-aed5-1485ba6b5583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "df_t=df\n",
    "forest=[]\n",
    "for g in set(list(df_t.group)):\n",
    "    df_tree=df_t[df_t.group==g]\n",
    "    graph = nx.DiGraph()\n",
    "    parents=df_tree['parent'].tolist()\n",
    "    children=df_tree['child'].tolist()\n",
    "    probabilities=df_tree['predict'].tolist()\n",
    "    nodes = set(parents + children)\n",
    "    for node in nodes:\n",
    "        graph.add_node(node)\n",
    "    for i in range(len(parents)):\n",
    "        graph.add_edge(parents[i], children[i], weight=probabilities[i])\n",
    "    T=nx.maximum_spanning_arborescence(graph)\n",
    "    df=nx.to_pandas_edgelist(T)\n",
    "    df['group']=g\n",
    "    forest.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a30cee8-b62e-4cd8-bb1f-10045d3bc9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_v2=pd.concat(forest, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1dc3f75-c1d6-4b3c-8664-6993acfbd367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "665    49\n",
       "682    48\n",
       "685    40\n",
       "662    39\n",
       "683    39\n",
       "       ..\n",
       "677    10\n",
       "732    10\n",
       "727    10\n",
       "705    10\n",
       "737    10\n",
       "Name: group, Length: 108, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_v2.columns=['parent','child','weight','group']\n",
    "res_v2['compare']=res_v2['parent']+res_v2['child']+res_v2['group'].astype(str)\n",
    "res_v2['group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa3f2688-5afb-4d8f-898f-98a8e16475e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual=pd.read_csv('actual.csv')\n",
    "df_actual=df_actual[df_actual['group']>= 647]\n",
    "df_actual['compare']=df_actual['parent']+df_actual['child']+df_actual['group'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87651263-deca-4a72-b8ce-8b455f8dfa1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>parent</th>\n",
       "      <th>child</th>\n",
       "      <th>group</th>\n",
       "      <th>flag</th>\n",
       "      <th>predict</th>\n",
       "      <th>label</th>\n",
       "      <th>compare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12869</td>\n",
       "      <td>12869</td>\n",
       "      <td>dominance</td>\n",
       "      <td>absolutism</td>\n",
       "      <td>647</td>\n",
       "      <td>True</td>\n",
       "      <td>0.720197</td>\n",
       "      <td>1</td>\n",
       "      <td>dominanceabsolutism647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12870</td>\n",
       "      <td>12870</td>\n",
       "      <td>dominance</td>\n",
       "      <td>ascendant</td>\n",
       "      <td>647</td>\n",
       "      <td>True</td>\n",
       "      <td>0.731368</td>\n",
       "      <td>1</td>\n",
       "      <td>dominanceascendant647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12871</td>\n",
       "      <td>12871</td>\n",
       "      <td>dominance</td>\n",
       "      <td>domination</td>\n",
       "      <td>647</td>\n",
       "      <td>True</td>\n",
       "      <td>0.759397</td>\n",
       "      <td>1</td>\n",
       "      <td>dominancedomination647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12872</td>\n",
       "      <td>12872</td>\n",
       "      <td>domination</td>\n",
       "      <td>transcendence</td>\n",
       "      <td>647</td>\n",
       "      <td>True</td>\n",
       "      <td>0.729613</td>\n",
       "      <td>1</td>\n",
       "      <td>dominationtranscendence647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12873</td>\n",
       "      <td>12873</td>\n",
       "      <td>dominance</td>\n",
       "      <td>dominion</td>\n",
       "      <td>647</td>\n",
       "      <td>True</td>\n",
       "      <td>0.705614</td>\n",
       "      <td>1</td>\n",
       "      <td>dominancedominion647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>14872</td>\n",
       "      <td>14872</td>\n",
       "      <td>rain</td>\n",
       "      <td>shower</td>\n",
       "      <td>754</td>\n",
       "      <td>True</td>\n",
       "      <td>0.841348</td>\n",
       "      <td>1</td>\n",
       "      <td>rainshower754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>14873</td>\n",
       "      <td>14873</td>\n",
       "      <td>rain</td>\n",
       "      <td>sprinkle</td>\n",
       "      <td>754</td>\n",
       "      <td>True</td>\n",
       "      <td>0.725750</td>\n",
       "      <td>1</td>\n",
       "      <td>rainsprinkle754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>14874</td>\n",
       "      <td>14874</td>\n",
       "      <td>precipitate</td>\n",
       "      <td>sleet</td>\n",
       "      <td>754</td>\n",
       "      <td>True</td>\n",
       "      <td>0.306711</td>\n",
       "      <td>1</td>\n",
       "      <td>precipitatesleet754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>14875</td>\n",
       "      <td>14875</td>\n",
       "      <td>precipitate</td>\n",
       "      <td>snow</td>\n",
       "      <td>754</td>\n",
       "      <td>True</td>\n",
       "      <td>0.493274</td>\n",
       "      <td>1</td>\n",
       "      <td>precipitatesnow754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>14876</td>\n",
       "      <td>14876</td>\n",
       "      <td>precipitate</td>\n",
       "      <td>spat</td>\n",
       "      <td>754</td>\n",
       "      <td>True</td>\n",
       "      <td>0.416163</td>\n",
       "      <td>1</td>\n",
       "      <td>precipitatespat754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2008 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0.1  Unnamed: 0       parent          child  group  flag  \\\n",
       "0            12869       12869    dominance     absolutism    647  True   \n",
       "1            12870       12870    dominance      ascendant    647  True   \n",
       "2            12871       12871    dominance     domination    647  True   \n",
       "3            12872       12872   domination  transcendence    647  True   \n",
       "4            12873       12873    dominance       dominion    647  True   \n",
       "...            ...         ...          ...            ...    ...   ...   \n",
       "2003         14872       14872         rain         shower    754  True   \n",
       "2004         14873       14873         rain       sprinkle    754  True   \n",
       "2005         14874       14874  precipitate          sleet    754  True   \n",
       "2006         14875       14875  precipitate           snow    754  True   \n",
       "2007         14876       14876  precipitate           spat    754  True   \n",
       "\n",
       "       predict  label                     compare  \n",
       "0     0.720197      1      dominanceabsolutism647  \n",
       "1     0.731368      1       dominanceascendant647  \n",
       "2     0.759397      1      dominancedomination647  \n",
       "3     0.729613      1  dominationtranscendence647  \n",
       "4     0.705614      1        dominancedominion647  \n",
       "...        ...    ...                         ...  \n",
       "2003  0.841348      1               rainshower754  \n",
       "2004  0.725750      1             rainsprinkle754  \n",
       "2005  0.306711      1         precipitatesleet754  \n",
       "2006  0.493274      1          precipitatesnow754  \n",
       "2007  0.416163      1          precipitatespat754  \n",
       "\n",
       "[2008 rows x 9 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a78d9804-fbd9-4dca-a5f6-324cfbbe8bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual.merge(res_v2, on='compare',how='left').to_csv('/notebooks/group_wise_test_rs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8998061d-999f-47b5-9b88-b57f5258cbc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6130478087649402"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_actual.merge(res_v2, on='compare'))/len(df_actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dc242a-08f8-4430-83f8-931b4e5c276e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
